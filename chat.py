import streamlit as st
from ollama import Client
from config import OLLAMA_API_KEY
from models import get_cloud_models
import time


def stream_file_summary(file_content, selected_model, api_key, filename):
    """åœ¨å°è©±å€åŸŸä¸­å³æ™‚ä¸²æµé¡¯ç¤ºæ–‡ä»¶æ‘˜è¦"""
    client = Client(
        host="https://ollama.com",
        headers={"Authorization": f"Bearer {api_key}"}
    )
    
    summary = ""
    
    # å¿…é ˆåœ¨å°è©±å€åŸŸå…§å³æ™‚é¡¯ç¤º
    with st.chat_message("assistant"):
        status_placeholder = st.empty()
        status_placeholder.info("ğŸ“„ æ­£åœ¨æ•´ç†æ–‡ä»¶é‡é»...")
        
        summary_placeholder = st.empty()
        
        try:
            # å³æ™‚ä¸²æµ
            for part in client.chat(
                selected_model,
                messages=[{
                    "role": "user",
                    "content": f"è«‹å¹«æˆ‘æ•´ç†ä»¥ä¸‹æ–‡ä»¶é‡é»å…§å®¹ï¼Œä¸¦ç”¨æ¢åˆ—æ–¹å¼åˆ—å‡ºï¼š\n{file_content}"
                }],
                stream=True
            ):
                summary += part["message"]["content"]
                # å³æ™‚æ›´æ–°ï¼ŒåŠ ä¸Šæ¸¸æ¨™
                summary_placeholder.markdown(f"### ğŸ“ æ–‡ä»¶é‡é»æ‘˜è¦\n{summary}â–Œ")
            
            # å®Œæˆå¾Œç§»é™¤æ¸¸æ¨™
            summary_placeholder.markdown(f"### ğŸ“ æ–‡ä»¶é‡é»æ‘˜è¦\n{summary}")
            status_placeholder.empty()
            
            # ä¿å­˜æ‘˜è¦
            st.session_state["uploaded_text"] = summary
            
            # æ·»åŠ åˆ°å°è©±è¨˜éŒ„
            st.session_state["messages"].append({
                "role": "assistant",
                "content": f"### ğŸ“ æ–‡ä»¶é‡é»æ‘˜è¦\n{summary}\n\nâœ… å·²æ•´ç†æ–‡ä»¶ï¼š{filename}"
            })
            
            return True
            
        except Exception as e:
            summary_placeholder.error(f"âš ï¸ æ‘˜è¦ç”ŸæˆéŒ¯èª¤ï¼š{e}")
            return False


# --- 2. ä¸»èŠå¤©ä»‹é¢ ---
def ollama_chat():
    st.title("ğŸ’¬ Chat with Ollama Cloud")
    
    st.divider()

    # æ·»åŠ  CSS æ§åˆ¶å¸ƒå±€
    st.markdown("""
        <style>
        /* è¨­ç½®ä¸»å®¹å™¨é«˜åº¦ */
        .main .block-container {
            padding-bottom: 150px;
        }
        
        /* è®“å°è©±å€åŸŸå¯æ»¾å‹• */
        .stChatMessage {
            margin-bottom: 1rem;
        }
        </style>
    """, unsafe_allow_html=True)

    api_key = OLLAMA_API_KEY

    if "messages" not in st.session_state:
        st.session_state["messages"] = []
    if "uploaded_text" not in st.session_state:
        st.session_state["uploaded_text"] = ""
    if "last_uploaded_file" not in st.session_state:
        st.session_state["last_uploaded_file"] = None
    if "processing_file" not in st.session_state:
        st.session_state["processing_file"] = False

    if "user" not in st.session_state:
        st.error("è«‹å…ˆç™»å…¥")
        return

    username = st.session_state["user"]

    # --- Sidebar ---
    with st.sidebar:
        st.success(f"å¸³è™Ÿï¼š{username}")

        models = get_cloud_models(api_key)
        selected_model = (
            st.selectbox("é¸æ“‡æ¨¡å‹", models, key="model_select")
            if models else None
        )

        st.divider()

        if st.button("ğŸ—‘ï¸ æ¸…ç©ºå°è©±", use_container_width=True):
            st.session_state["messages"] = []
            st.session_state["uploaded_text"] = ""
            st.session_state["last_uploaded_file"] = None
            st.session_state["processing_file"] = False
            st.rerun()

        if st.button("ğŸšª ç™»å‡º", use_container_width=True):
            st.session_state.clear()
            st.rerun()

    # --- å°è©±å€åŸŸ ---
    chat_container = st.container()
    
    with chat_container:
        # é¡¯ç¤ºæ­·å²å°è©±
        if st.session_state["messages"]:
            for msg in st.session_state["messages"]:
                with st.chat_message(msg["role"]):
                    st.markdown(msg["content"])
        else:
            # ç•¶æ²’æœ‰å°è©±æ™‚ï¼Œé¡¯ç¤ºæ­¡è¿è¨Šæ¯
            st.markdown("""
                <div style='text-align: center; padding: 100px 20px; color: #666;'>
                    <h3>ğŸ‘‹ æ­¡è¿ä½¿ç”¨ Ollama Cloud èŠå¤©</h3>
                    <p>é–‹å§‹å°è©±æˆ–ä¸Šå‚³æ–‡ä»¶ä¾†ç²å–æ‘˜è¦</p>
                </div>
            """, unsafe_allow_html=True)

    # --- å›ºå®šåœ¨åº•éƒ¨çš„åŠŸèƒ½å€åŸŸ ---
    st.markdown("<br>" * 4, unsafe_allow_html=True)
    
    # æ–‡ä»¶ä¸Šå‚³å™¨
    uploaded_file = st.file_uploader(
        "ğŸ“„ ä¸Šå‚³æ–‡ä»¶ï¼ˆæ”¯æ´ txt, csv, mdï¼‰",
        type=["txt", "csv", "md"],
        key="file_uploader"
    )

    # è™•ç†æ–‡ä»¶ä¸Šå‚³
    if uploaded_file and not st.session_state["processing_file"]:
        if st.session_state["last_uploaded_file"] != uploaded_file.name:
            st.session_state["processing_file"] = True
            
            # è®€å–æ–‡ä»¶å…§å®¹
            file_content = uploaded_file.read().decode("utf-8")
            
            # åœ¨å°è©±å€åŸŸä¸­ä¸²æµé¡¯ç¤ºæ‘˜è¦
            success = stream_file_summary(file_content, selected_model, api_key, uploaded_file.name)
            
            if success:
                st.session_state["last_uploaded_file"] = uploaded_file.name
            
            st.session_state["processing_file"] = False
            st.rerun()

    # --- èŠå¤©è¼¸å…¥ ---
    if prompt := st.chat_input("åœ¨æ­¤è¼¸å…¥è¨Šæ¯..."):
        # é¡¯ç¤ºç”¨æˆ¶æ¶ˆæ¯
        st.session_state["messages"].append({
            "role": "user",
            "content": prompt
        })

        full_prompt = prompt
        if st.session_state.get("uploaded_text"):
            full_prompt = (
                f"ã€åƒè€ƒæ–‡ä»¶æ‘˜è¦ã€‘\n{st.session_state['uploaded_text']}\n\n"
                f"ã€ç”¨æˆ¶å•é¡Œã€‘\n{prompt}"
            )

        client = Client(
            host="https://ollama.com",
            headers={"Authorization": f"Bearer {api_key}"}
        )

        # åœ¨å°è©±å€åŸŸé¡¯ç¤ºåŠ©æ‰‹å›æ‡‰
        with st.chat_message("assistant"):
            resp_placeholder = st.empty()
            full_resp = ""

            try:
                context_msgs = st.session_state["messages"] + [
                    {"role": "user", "content": full_prompt}
                ]

                for part in client.chat(
                    selected_model,
                    messages=context_msgs[:-1] + [{"role": "user", "content": full_prompt}],
                    stream=True
                ):
                    full_resp += part["message"]["content"]
                    resp_placeholder.markdown(full_resp + "â–Œ")

                resp_placeholder.markdown(full_resp)

                st.session_state["messages"].append({
                    "role": "assistant",
                    "content": full_resp
                })

            except Exception as e:
                st.error(f"Ollama éŒ¯èª¤ï¼š{e}")
        
        st.rerun()